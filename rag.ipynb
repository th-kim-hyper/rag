{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd5157e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import PurePath\n",
    "from pydoc import doc\n",
    "import re\n",
    "from turtle import title\n",
    "from typing import Literal, Optional, Union\n",
    "from xml.dom.minidom import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from regex import D\n",
    "from sqlalchemy import false\n",
    "import fitz # PyMuPDF\n",
    "\n",
    "file_path = \"./docs/국가계약법_시행규칙.pdf\"\n",
    "\n",
    "class HiPDFLoader(PyPDFLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: Union[str, PurePath],\n",
    "        separators: Optional[list[str]] = ['^제[1-9][0-9]*장 .+$', '^제[1-9][0-9]*조\\\\(.+\\\\)$'],\n",
    "        header_margin=50,\n",
    "        footer_margin=50) -> None:\n",
    "        super().__init__(file_path=file_path)\n",
    "        self.file_path = file_path\n",
    "        self.header_margin = header_margin\n",
    "        self.footer_margin = footer_margin\n",
    "        self.separators = separators\n",
    "        \n",
    "    def load(self, split:bool = False) -> list[Document]:\n",
    "        docs = self.trim_header_footer()\n",
    "        return self.split(docs) if split else docs\n",
    "        \n",
    "    def split(self, docs:list[Document]) -> list[Document]:\n",
    "        split_doc = []\n",
    "        \n",
    "        for doc in docs:\n",
    "            text_splitter = CharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=200,\n",
    "                separator=\"\\n\",\n",
    "                )\n",
    "            splits = text_splitter.split_text(doc.page_content)\n",
    "            split_docs = []\n",
    "            for j, split in enumerate(splits):\n",
    "                new_doc = Document()\n",
    "                new_doc.page_content = split\n",
    "                new_doc.metadata = {\n",
    "                    \"source\": doc.metadata['source'],\n",
    "                    \"page\": doc.metadata['page'],\n",
    "                    \"total_pages\": doc.metadata['total_pages'],\n",
    "                    \"chunk\": j,\n",
    "                    }\n",
    "                split_docs.append(new_doc)\n",
    "            split_doc.extend(split_docs)\n",
    "        # pages = [doc.page_content for doc in docs]\n",
    "        # metadatas = [doc.metadata for doc in docs]\n",
    "        # full_text = '\\n\\n'.join(pages)\n",
    "        # title = docs[0].page_content.lstrip()\n",
    "        # re.compile(p)\n",
    "        # abbreviation = ''\n",
    "        return split_doc\n",
    "\n",
    "    def trim_header_footer(self) -> list[Document]:\n",
    "        docs = []\n",
    "        clean_pages = []\n",
    "        pages = fitz.open(self.file_path)\n",
    "        title = os.path.basename(self.file_path)\n",
    "        patterns = [re.compile(p) for p in self.separators]\n",
    "\n",
    "        for page in pages:\n",
    "            # 페이지 전체 크기 (width, height)\n",
    "            page_rect = page.rect\n",
    "            \n",
    "            # 제외할 영역을 뺀 '본문 영역' 정의\n",
    "            # fitz.Rect(x0, y0, x1, y1) -> 좌상단(x0, y0), 우하단(x1, y1)\n",
    "            content_box = fitz.Rect(\n",
    "                0,                     # 왼쪽 끝\n",
    "                self.header_margin,         # 위에서 머리말만큼 아래로\n",
    "                page_rect.width,       # 오른쪽 끝\n",
    "                page_rect.height - self.footer_margin  # 아래에서 꼬리말만큼 위로\n",
    "            )\n",
    "            \n",
    "            # 해당 영역(crop box) 내부의 텍스트만 추출\n",
    "            text = page.get_text('text', clip=content_box).lstrip().rstrip()\n",
    "            lines = text.lstrip().split('\\n')\n",
    "            page_number = page.number + 1\n",
    "            \n",
    "            if page_number == 1:\n",
    "                title = lines[0] if lines else title\n",
    "            \n",
    "            doc = None\n",
    "            jang = []\n",
    "            \n",
    "            for line in lines:\n",
    "                for p in patterns:\n",
    "                    match = p.search(line)\n",
    "                    if match:\n",
    "                        doc = match.group(0)\n",
    "                        break\n",
    "                if doc:\n",
    "                    break\n",
    "\n",
    "            document = Document()\n",
    "            document.page_content = text\n",
    "            document.metadata = {\n",
    "                \"page\": page.number,\n",
    "                'source': self.file_path,\n",
    "                'title': title,\n",
    "                'total_pages': len(pages),\n",
    "                'jang': jang,\n",
    "                # 'matchs': [sep for sep in self.separators if re.search(sep, text, re.MULTILINE)]\n",
    "                }\n",
    "            docs.append(document)\n",
    "\n",
    "                    \n",
    "            \n",
    "            # p_jang = re.compile(self.separators[0])\n",
    "            \n",
    "            # jang_matches = p_jang.search(text, re.MULTILINE)\n",
    "            # if jang_matches:\n",
    "            #     for line in lines:\n",
    "            #         jang_match = p_jang.search(line)\n",
    "            #         if jang_match:\n",
    "            #             jang.append(jang_match.group(0))\n",
    "            #             break\n",
    "            #     jang_match = p_jang.search(text, re.MULTILINE)\n",
    "            #     if jang_match:\n",
    "            #         jang = jang_match.group(0)\n",
    "                \n",
    "            # clean_pages.append(text)\n",
    "            # document = Document()\n",
    "            # document.page_content = text\n",
    "            # document.metadata = {\n",
    "            #     \"page\": page.number,\n",
    "            #     'source': self.file_path,\n",
    "            #     'title': title,\n",
    "            #     'total_pages': len(pages),\n",
    "            #     'jang': jang,\n",
    "            #     # 'matchs': [sep for sep in self.separators if re.search(sep, text, re.MULTILINE)]\n",
    "            #     }\n",
    "            # docs.append(document)\n",
    "            \n",
    "        return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f691025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 0,\n",
       " 'source': './docs/국가계약법_시행규칙.pdf',\n",
       " 'title': '국가를 당사자로 하는 계약에 관한 법률 시행규칙 ( 약칭: 국가계약법 시행규칙 )',\n",
       " 'total_pages': 24,\n",
       " 'jang': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = HiPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "# docs\n",
    "# # --- 본문(first body) 첫줄 추출 로직 ---\n",
    "# full_text = '\\n\\n'.join([d.page_content for d in docs]) if docs else \"\"\n",
    "\n",
    "# --- 끝 ---\n",
    "docs[0].metadata\n",
    "docs[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
